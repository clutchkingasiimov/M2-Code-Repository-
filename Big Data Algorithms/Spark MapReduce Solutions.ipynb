{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/clutchkingasiimov/BigDataAlgorithms/blob/main/ass4_map_reduce_spark_colab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JfstpKhUM8x7"
      },
      "source": [
        "<h1><center>Big Data Algorithms Techniques & Platforms</center></h1>\n",
        "<h2>\n",
        "<hr style=\" border:none; height:3px;\">\n",
        "<center>Assignment 4 - MapReduce and Spark</center>\n",
        "<hr style=\" border:none; height:3px;\">\n",
        "</h2>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JWwndZSiM8x8"
      },
      "source": [
        "# Introduction\n",
        "\n",
        "\n",
        "<p align=\"justify\">\n",
        "<font size=\"3\">\n",
        "In this exercise you is asked to use Spark for implementing an algorithm that applies computations on documents and dataframes.\n",
        "</font>\n",
        "</p>\n",
        "\n",
        "<p align=\"justify\">\n",
        "<hr style=\" border:none; height:2px;\">\n",
        " <font  size=\"3\" color='#91053d'>**Execute the following cell in order to initialize Spark**</font>\n",
        "<hr style=\" border:none; height:2px;\">\n",
        "</p>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "3shtJGpOM8x8"
      },
      "outputs": [],
      "source": [
        "# !apt-get update\n",
        "# !apt-get install openjdk-8-jdk-headless -qq > /dev/null\n",
        "# !wget -q https://downloads.apache.org/spark/spark-3.0.3/spark-3.0.3-bin-hadoop2.7.tgz\n",
        "# !tar zxvf spark-3.0.3-bin-hadoop2.7.tgz\n",
        "# !pip install -q findspark\n",
        "\n",
        "import os\n",
        "import re\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "os.environ[\"SPARK_HOME\"] = \"/content/spark-3.0.3-bin-hadoop2.7\"\n",
        "\n",
        "\n",
        "import findspark\n",
        "findspark.init()\n",
        "\n",
        "#import of the SparkSession\n",
        "import pyspark \n",
        "from pyspark.sql import SparkSession\n",
        "\n",
        "#inizialization of the Spark Session\n",
        "spark = SparkSession \\\n",
        "    .builder \\\n",
        "    .appName(\"Assignment4\") \\\n",
        "    .getOrCreate()\n",
        "\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KK49MFw9M8yA"
      },
      "source": [
        "# Analysing documents\n",
        "\n",
        "\n",
        "<p align=\"justify\">\n",
        "<font size=\"3\">\n",
        "We have already seen that MapReduce procedures are good in analyzing text-files.\n",
        "    \n",
        "The provided data comes from a scraping operation on the website https://www.vagalume.com.br/ and is available on kaggle:\n",
        "    \n",
        "https://www.kaggle.com/neisse\n",
        "    \n",
        "\n",
        "    \n",
        "The assignment is divided in 2 parts:\n",
        "    \n",
        "* Part 1 is focused on MapReduce \n",
        "    \n",
        "* Part 2  is focuses on dataframes\n",
        "    </font>\n",
        "    </p>\n",
        "    \n",
        "<p align=\"justify\">\n",
        "<hr style=\" border:none; height:2px;\">\n",
        " <font  size=\"3\" color='#91053d'>Notice that  dataset is noisy and shows all the typical issues related with data coming from this procedure (duplicated entries, etc).</font>\n",
        "<hr style=\" border:none; height:2px;\">\n",
        "</p>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rdoAnmVuN7fj"
      },
      "source": [
        "# Part 1 -  MapReduce\n",
        "<p align=\"justify\">\n",
        "<font size=\"3\">\n",
        "In the provided folder you can find a set of documents/files containing  descriptions of songs (lyrics and additional informations). Specifically in each file:\n",
        "\n",
        "- the first line is the idiom/language\n",
        "- the second line is the title of a song\n",
        "- the third line is the relative url of the song of the original website\n",
        "- from fourth line on the text you find the lyrics of the song.\n",
        "    </font>\n",
        "    </p>\n",
        "\n",
        "## Exercise 1 - (2 points) - Song's lyrics \n",
        "\n",
        "<p align=\"justify\">\n",
        "<font size=\"3\">\n",
        "Provide a Spark MapReduce procedure that reads the documents and checks how many song's lyrics appear at least two times.\n",
        "\n",
        "In the data-interpretation of this exercise you can consider that two files represent the same lyric if the url (3rd line of each file) is the same.\n",
        "\n",
        " </font>\n",
        "</p>\n",
        "\n",
        "<p align=\"justify\">\n",
        "<hr style=\" border:none; height:2px;\">\n",
        " <font  size=\"3\" color='#91053d'>Notice that  you can reuse any code that was made available for the previous labs/assignments or that you already developed in these contexts.</font>\n",
        "<hr style=\" border:none; height:2px;\">\n",
        "</p>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xhXehCgaX7sp"
      },
      "outputs": [],
      "source": [
        "#Unzipping the file to extract the folder \n",
        "!unzip /content/lyrics_files_idioms.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "cieLWOB4YWiM"
      },
      "outputs": [],
      "source": [
        "#Coroutine function for loading the files \n",
        "#This coroutine file will work as a mapper function \n",
        "def file_opener(file_input):\n",
        "    fle = file_input[1]\n",
        "    contents = re.compile(r'\\n').split(fle)\n",
        "    url = contents[1]\n",
        "    return url, 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "0cAoEVqsmIsI"
      },
      "outputs": [],
      "source": [
        "#Let's see a random file inside the folder \n",
        "import shutil \n",
        "path = \"/content/lyrics_files_idioms\"\n",
        "dir_list = os.listdir(path)\n",
        "first_1500 = dir_list[:15000]\n",
        "\n",
        "# new_dir = os.mkdir(\"/content/lyrics_files_idioms_small\")\n",
        "for files in first_1500:\n",
        "    shutil.copy(\"/content/lyrics_files_idioms/\"+files, \"/content/lyrics_files_idioms_small\")\n",
        "\n",
        "# len(os.listdir(\"content/lyrics_files_idioms_small\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w2FUUVfRN7fl",
        "outputId": "ae465184-481b-40b4-9005-89e036c86d85"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Duplicate links: 38096\n"
          ]
        }
      ],
      "source": [
        "### Write here your code\n",
        "from pyspark import SparkConf, SparkContext \n",
        "conf = SparkConf().setMaster(\"local\")\n",
        "sc = SparkContext.getOrCreate(conf=conf)\n",
        "\n",
        "#wholeTextFiles is a method that allows us to read text files quickly\n",
        "lyrics_file = sc.wholeTextFiles(\"/content/lyrics_files_idioms/*\")\n",
        "links = lyrics_file.map(file_opener) #We use the coroutine mentioned above\n",
        "duplicates = links.reduceByKey(lambda x,y: x+y).filter(lambda x: x[1] > 1)\n",
        "print(f\"Duplicate links: {duplicates.count()}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_TsPvNf-uwZq",
        "outputId": "8a7f6edb-cdef-44cc-9493-aad0dd055b93"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "duplicates.count()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D6nrre6RN7fm"
      },
      "source": [
        "## Exercise 2\n",
        "\n",
        "### 2.1 - (1 point) - Distinct songs\n",
        "Provide a Spark MapReduce procedure that provides how many distinct song's lyrics are present.\n",
        "\n",
        "Also in this case consider the uri as key: two files represent the same lyric if the url is equal.\n",
        "\n",
        "### 2.2 - (1 point) - Chaining MapReduce steps\n",
        "According to your implementation of Exercise 1, can you chain MapReduce additional MapReduce steps for solving Exercise 2.1? \n",
        "\n",
        "Provide the code for 2.1 and anwer for 2.2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-XzgejwA1Ase"
      },
      "outputs": [],
      "source": [
        "#Show all the links in the text files\n",
        "for link in links.collect():\n",
        "    print(link)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XldwuJVrGxTn"
      },
      "source": [
        "As seen above, the text file consists of the first line as the language."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ULPUzjGR1Uho",
        "outputId": "a9a8f80c-3c49-46d5-f11f-af808b1aad73"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "167499"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ],
      "source": [
        "### Write here your code followed by the answer to question 2.1\n",
        "links.reduceByKey(lambda x,y: x+y).count()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UEyyrG3i33wR",
        "outputId": "07144cdd-f736-4eaa-84f6-408e7b1cf008"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1500"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "links.count()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NeLV-VA83PVR"
      },
      "source": [
        "For Question 2, a convenient method to detect the number of duplicates is to take the total count of the documents and subtract the duplicates from the document. The solution has already been implemented in Question 1 already."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QDXuIlhmN7fo"
      },
      "source": [
        "# Exercise 3\n",
        "\n",
        "### 3.1 - (3 points) - Most common word for language\n",
        "\n",
        "Now that you discovered the duplicated documents consider just one occurence of each song's lyric and define a MapReduce procedure that finds the most common word for each language (of course you must remove stop words).\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {
        "id": "rkWJ5Pk3N7fq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "13b4bab3-2383-42b4-9fef-a0106c4cf31f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('Portuguese', ('pra', 146459)),\n",
              " ('English', ('love', 144789)),\n",
              " ('Kinyarwanda', ('ni', 712)),\n",
              " ('German', ('komm', 192)),\n",
              " ('Danish', ('forever', 105)),\n",
              " ('Tagalog', ('ang', 79)),\n",
              " ('Irish', ('me', 67)),\n",
              " ('Swedish', ('a', 54)),\n",
              " ('Malagasy', ('me', 38)),\n",
              " ('Norwegian', ('vestido', 32)),\n",
              " ('Catalan', ('tu', 29)),\n",
              " ('Swahili', ('pouss', 28)),\n",
              " ('Russian', ('стиле', 25)),\n",
              " ('Turkish', ('loco', 19)),\n",
              " ('Korean', ('you', 16)),\n",
              " ('Bosnian', ('je', 8)),\n",
              " ('Polish', ('policz', 6)),\n",
              " ('Hungarian', ('virágom', 4)),\n",
              " ('Romanian', (\"pe'\", 3)),\n",
              " ('Spanish', ('amor', 6698)),\n",
              " ('French', ('the', 755)),\n",
              " ('Italian', (\"c'è\", 417)),\n",
              " ('Icelandic', ('og', 128)),\n",
              " ('Japanese', ('huh', 66)),\n",
              " ('Dutch', ('nimma', 40)),\n",
              " ('Indonesian', ('i', 40)),\n",
              " ('Galician', ('paso', 36)),\n",
              " ('Sundanese', ('you', 34)),\n",
              " ('Finnish', ('the', 34)),\n",
              " ('Arabic', ('y', 21)),\n",
              " ('Estonian', ('jää', 20)),\n",
              " ('Slovak', ('uncoolohol', 16)),\n",
              " ('Czech', ('senta', 13)),\n",
              " ('Serbian', ('i', 13)),\n",
              " ('Basque', ('nire', 12)),\n",
              " ('Kurdish', ('kevin', 12)),\n",
              " ('Croatian', ('æe', 11)),\n",
              " ('Malay', ('the', 9)),\n",
              " ('Welsh', ('mae', 8)),\n",
              " ('Afrikaans', ('alles', 3))]"
            ]
          },
          "metadata": {},
          "execution_count": 77
        }
      ],
      "source": [
        "### Write here your code\n",
        "\n",
        "#First we load a stopword file in a json format \n",
        "import json \n",
        "from collections import defaultdict\n",
        "\n",
        "with open(\"/content/stopwords-all.json\",\"r\") as stop_file:\n",
        "    stopword = json.load(stop_file)\n",
        "\n",
        "#Storing the stopwords in a defaultdict to track them. \n",
        "stopwords = defaultdict(list)\n",
        "for key, value in stopword.items():\n",
        "    stopwords[key] = value\n",
        "\n",
        "#Storing the ISO codes in a defaultdict \n",
        "iso_codes = defaultdict(str)\n",
        "with open(\"/content/iso_codes.txt\",\"r\") as codes:\n",
        "    lines = codes.readlines()\n",
        "    for line in lines: \n",
        "        iso_code = line.split()[0].replace(\"'\",'').replace(\"(\",'')\\\n",
        "        .replace(\")\",'').replace(\",\",'')\n",
        "        language = line.split()[1].replace(\"'\",'').replace(\"(\",'')\\\n",
        "        .replace(\")\",'').replace(\",\",'').replace(\";\",'')\n",
        "        iso_codes[language] = iso_code\n",
        "\n",
        "#Define a coroutine for finding the song words from each song \n",
        "def song_words(file_input):\n",
        "    fle = file_input[1]\n",
        "    contents = re.compile(r'\\n').split(fle)\n",
        "    lang = contents[0].title()\n",
        "    #Find the ISO code that reflects the language \n",
        "    iso_code = iso_codes[lang]\n",
        "    \n",
        "            \n",
        "    # # #Extract the song lyrics and lower string, and remove special characters\n",
        "    lyrics = contents[3].lower()\n",
        "    lyrics = re.compile(r\"[.:;,\\s\\?!\\[\\]\\(\\)\\\"&\\*/]+\").split(lyrics)\n",
        "    if iso_code != '':\n",
        "        song_stopwords = stopwords[iso_code]\n",
        "        cleaned_words = [word for word in lyrics if word not in song_stopwords]\n",
        "        return lang, tuple(cleaned_words)\n",
        "    else:\n",
        "        return 'Na',tuple()\n",
        "\n",
        "top_words = lyrics_file.map(song_words)\\\n",
        "    .filter(lambda x : x[0] != 'Na')\\\n",
        "    .distinct()\\\n",
        "    .flatMapValues(lambda x: x)\\\n",
        "    .map(lambda x: ((x[0], x[1]), 1))\\\n",
        "    .reduceByKey(lambda x, y: x + y)\\\n",
        "    .map(lambda x: (x[0][0], (x[0][1], x[1])))\\\n",
        "    .sortBy(lambda x: x[1][1],ascending=False)\\\n",
        "    .groupByKey()\\\n",
        "    .mapValues(list)\\\n",
        "    .mapValues(lambda x: (x[0]))\n",
        "\n",
        "top_words.collect()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# os.chdir(\"\")\n",
        "\n",
        "# os.listdir(\"..\")\n",
        "\n",
        "# f = open(\"/content/lyrics_files_idioms_small\", \"r\")\n",
        "# contents = re.compile(r'\\n').split(f.read())\n",
        "# lol = stopwords[iso_codes[contents[0].title()]]\n",
        "# lyrics =re.compile(r\"[.:;,\\s\\?!\\[\\]\\(\\)\\\"&\\*/]+\").split(contents[3].lower())\n",
        "# cleaned_words = [word for word in lyrics if word not in lol]"
      ],
      "metadata": {
        "id": "QebCTaytVv04"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1lFUNovsN7fs"
      },
      "source": [
        "### 3.2 - (3 points) - Most common end/start words\n",
        "\n",
        "Finally discover, for each language, the most common ending and starting word (of course, also in this case) you must remove stop words)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {
        "id": "qY5-rpJ2N7fs"
      },
      "outputs": [],
      "source": [
        "### Write here your code\n",
        "\n",
        "#First we load a stopword file in a json format \n",
        "import json \n",
        "from collections import defaultdict\n",
        "\n",
        "with open(\"/content/stopwords-all.json\",\"r\") as stop_file:\n",
        "    stopword = json.load(stop_file)\n",
        "\n",
        "#Storing the stopwords in a defaultdict to track them. \n",
        "stopwords = defaultdict(list)\n",
        "for key, value in stopword.items():\n",
        "    stopwords[key] = value\n",
        "\n",
        "#Storing the ISO codes in a defaultdict \n",
        "iso_codes = defaultdict(str)\n",
        "with open(\"/content/iso_codes.txt\",\"r\") as codes:\n",
        "    lines = codes.readlines()\n",
        "    for line in lines: \n",
        "        iso_code = line.split()[0].replace(\"'\",'').replace(\"(\",'')\\\n",
        "        .replace(\")\",'').replace(\",\",'')\n",
        "        language = line.split()[1].replace(\"'\",'').replace(\"(\",'')\\\n",
        "        .replace(\")\",'').replace(\",\",'').replace(\";\",'')\n",
        "        iso_codes[language] = iso_code\n",
        "\n",
        "#Define a coroutine for finding the song words from each song \n",
        "def song_firstlast_words(file_input):\n",
        "    fle = file_input[1]\n",
        "    contents = re.compile(r'\\n').split(fle)\n",
        "    lang = contents[0].title()\n",
        "    #Find the ISO code that reflects the language \n",
        "    iso_code = iso_codes[lang]\n",
        "    # # #Extract the song lyrics and lower string, and remove special characters\n",
        "    lyrics = contents[3].lower()\n",
        "    lyrics = re.compile(r\"[.:;,\\s\\?!\\[\\]\\(\\)\\\"&\\*/]+\").split(lyrics)\n",
        "    cleaned_lyrics = []\n",
        "    if iso_code != '':\n",
        "        song_stopwords = stopwords[iso_code]\n",
        "        cleaned_lyrics = [word for word in lyrics if word != '']\n",
        "        cleaned_words = [word for word in cleaned_lyrics if word not in song_stopwords]\n",
        "        if cleaned_words != []:\n",
        "            return lang, str(tuple(cleaned_words)[0]), str(tuple(cleaned_words)[-1])\n",
        "        else:\n",
        "            return lang, None, None \n",
        "    else:\n",
        "        return 'Na',tuple()\n",
        "\n",
        "\n",
        "#Extract the common words into a list \n",
        "common_words = lyrics_file.map(song_firstlast_words)\\\n",
        "    .filter(lambda x: x[0] != 'Na')\\\n",
        "    .filter(lambda x: x[2] != None)\\\n",
        "    .distinct()\\\n",
        "    .map(lambda x: (x[0], (x[1], x[2])))\\\n",
        "    .flatMapValues(lambda x: [(\"F\", x[0]), (\"L\", x[1])])\\\n",
        "    .map(lambda x: ((x[0], x[1][0], x[1][1]), 1))\\\n",
        "    .reduceByKey(lambda x,y : x+y)\\\n",
        "    .map(lambda x: ((x[0][0], x[0][1]),(x[0][2],x[1])))\\\n",
        "    .reduceByKey(lambda x,y: x if x[1] >= y[1] else y)\\\n",
        "    .sortBy(lambda x: x[0][0],ascending=False)\n",
        "    # .groupByKey()\\\n",
        "    # .mapValues(list)\n",
        "\n",
        "\n",
        "    # .map(lambda x: ((x[0][0], x[0][1]), (x[0][2], x[1])))\n",
        "    # .reduceByKey(lambda x, y: x[1] >= y[1])\n",
        "\n",
        "\n",
        "first_last_common_words = common_words.collect()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "first_last_common_words"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZGKA0u98pOIw",
        "outputId": "ebb59fb1-547b-4839-a36d-c18b748bde9d"
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(('Welsh', 'F'), ('sterling', 1)),\n",
              " (('Welsh', 'L'), ('mae', 1)),\n",
              " (('Turkish', 'L'), ('geci', 1)),\n",
              " (('Turkish', 'F'), ('just', 1)),\n",
              " (('Tagalog', 'L'), ('2x', 1)),\n",
              " (('Tagalog', 'F'), ('noong', 1)),\n",
              " (('Swedish', 'L'), ('minns', 1)),\n",
              " (('Swedish', 'F'), ('vet', 2)),\n",
              " (('Swahili', 'L'), ('day', 1)),\n",
              " (('Swahili', 'F'), ('so', 1)),\n",
              " (('Sundanese', 'F'), ('mayakovsky', 1)),\n",
              " (('Sundanese', 'L'), ('geoya', 1)),\n",
              " (('Spanish', 'F'), ('quiero', 83)),\n",
              " (('Spanish', 'L'), ('amor', 144)),\n",
              " (('Slovak', 'F'), ('the', 1)),\n",
              " (('Slovak', 'L'), ('uncool', 1)),\n",
              " (('Serbian', 'F'), ('srce', 1)),\n",
              " (('Serbian', 'L'), ('vjeènim', 1)),\n",
              " (('Russian', 'L'), ('a-ma-super-super-star', 1)),\n",
              " (('Russian', 'F'), ('муз', 2)),\n",
              " (('Romanian', 'L'), ('core', 1)),\n",
              " (('Romanian', 'F'), ('tenímmoce', 1)),\n",
              " (('Portuguese', 'L'), ('amor', 961)),\n",
              " (('Portuguese', 'F'), ('vou', 800)),\n",
              " (('Polish', 'L'), ('x2', 1)),\n",
              " (('Polish', 'F'), ('s³ucham', 1)),\n",
              " (('Norwegian', 'L'), ('veeei', 1)),\n",
              " (('Norwegian', 'F'), ('drøm', 1)),\n",
              " (('Malay', 'F'), ('dua', 1)),\n",
              " (('Malay', 'L'), ('selamanya', 1)),\n",
              " (('Malagasy', 'L'), ('oh-oh', 1)),\n",
              " (('Malagasy', 'F'), ('oe', 1)),\n",
              " (('Kurdish', 'F'), ('hi', 1)),\n",
              " (('Kurdish', 'L'), (\"da'\", 1)),\n",
              " (('Korean', 'L'), ('you', 1)),\n",
              " (('Korean', 'F'), ('넌', 1)),\n",
              " (('Kinyarwanda', 'L'), ('de', 3)),\n",
              " (('Kinyarwanda', 'F'), ('sora', 4)),\n",
              " (('Japanese', 'F'), ('rock', 1)),\n",
              " (('Japanese', 'L'), ('彼のために泣いているんだね', 1)),\n",
              " (('Italian', 'F'), (\"e'\", 9)),\n",
              " (('Italian', 'L'), ('amore', 10)),\n",
              " (('Irish', 'L'), ('baby', 1)),\n",
              " (('Irish', 'F'), (\"'n\", 1)),\n",
              " (('Indonesian', 'F'), ('ku', 1)),\n",
              " (('Indonesian', 'L'), ('bambeo', 1)),\n",
              " (('Icelandic', 'F'), ('ég', 4)),\n",
              " (('Icelandic', 'L'), ('hopelandic', 2)),\n",
              " (('Hungarian', 'L'), ('virágom', 1)),\n",
              " (('Hungarian', 'F'), ('tavaszi', 1)),\n",
              " (('German', 'L'), ('-', 5)),\n",
              " (('German', 'F'), ('liebe', 8)),\n",
              " (('Galician', 'F'), ('claridade', 1)),\n",
              " (('Galician', 'L'), ('relato…', 2)),\n",
              " (('French', 'F'), (\"c'est\", 13)),\n",
              " (('French', 'L'), ('amour', 5)),\n",
              " (('Finnish', 'F'), ('ilta', 1)),\n",
              " (('Finnish', 'L'), ('vaupauteen', 1)),\n",
              " (('Estonian', 'F'), (\"i'm\", 1)),\n",
              " (('Estonian', 'L'), ('õitseb', 1)),\n",
              " (('English', 'L'), ('love', 1194)),\n",
              " (('English', 'F'), ('intro', 776)),\n",
              " (('Dutch', 'F'), ('from', 1)),\n",
              " (('Dutch', 'L'), ('oh', 1)),\n",
              " (('Danish', 'L'), ('forever', 5)),\n",
              " (('Danish', 'F'), ('forever', 2)),\n",
              " (('Czech', 'F'), ('posso', 1)),\n",
              " (('Czech', 'L'), ('senta', 1)),\n",
              " (('Croatian', 'F'), ('zoru', 1)),\n",
              " (('Croatian', 'L'), ('vjeèna', 1)),\n",
              " (('Catalan', 'L'), ('azcapolanco', 1)),\n",
              " (('Catalan', 'F'), ('sents', 1)),\n",
              " (('Bosnian', 'L'), ('jasno', 1)),\n",
              " (('Bosnian', 'F'), ('oko', 1)),\n",
              " (('Basque', 'F'), ('bideak', 1)),\n",
              " (('Basque', 'L'), ('izanik', 1)),\n",
              " (('Arabic', 'F'), ('حاتم', 1)),\n",
              " (('Arabic', 'L'), (\"lejo'\", 1)),\n",
              " (('Afrikaans', 'F'), ('lede', 1)),\n",
              " (('Afrikaans', 'L'), ('yeah', 1))]"
            ]
          },
          "metadata": {},
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E-QgxsF1M8yB"
      },
      "source": [
        "\n",
        "<p align=\"justify\">\n",
        "<hr style=\" border:none; height:2px;\">\n",
        " <font  size=\"3\" color='#91053d'>**DataFrames**</font>\n",
        "<hr style=\" border:none; height:2px;\">\n",
        "</p>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CBkYMzzIM8yB",
        "outputId": "2f6a99b7-c42d-4401-9a7b-96628f3a0472"
      },
      "source": [
        "# Part 2 - Dataframes\n",
        "\n",
        "In this part you can use Pandas Dataframes or  Spark Dataframes.  I suggest to use a Spark Dataframe\n",
        "end exploit the Pandas functionalities as we have seen in the 2nd assignment. Download the two available datasets at the link:\n",
        "\n",
        "https://www.kaggle.com/neisse/scrapped-lyrics-from-6-genres\n",
        "\n",
        "You can find two .cvs files: \n",
        "\n",
        "* artists-data.csv\n",
        "\n",
        "* lyrics-data.csv\n",
        "\n",
        "\n",
        "# Import artist data.\n",
        "<p align=\"justify\">\n",
        "<font size=\"3\">\n",
        "The artist data in the .csv file can be stored in a dataframe. \n",
        "    \n",
        "Each row of the .csv file describes an artist and the columns represent the following data:\n",
        "    \n",
        "* Artist - The artist's name\n",
        "* Popularity - Popularity score at the date of scrapping\n",
        "* ALink - The link to the artist's page\n",
        "* AGenre - Primary musical genre of the artist\n",
        "* AGenres - A list (pay attention to the format) of genres the artist fits in\n",
        "    \n",
        "</font>\n",
        "</p>\n",
        "\n",
        "\n",
        "# Import song's lyrics data.\n",
        "\n",
        "\n",
        "<p align=\"justify\">\n",
        "<font size=\"3\">\n",
        "    \n",
        "Each row of the .csv file describes a lyric and the columns represent the following data:\n",
        "    \n",
        "* ALink - The link to the webpage of the artist\n",
        "* SLink - The link to the webpage of the song\n",
        "* Idiom - The idiom of the lyric\n",
        "* Lyric - The lyrics\n",
        "* SName - The name of the song\n",
        "\n",
        "    \n",
        "\n",
        "</font>\n",
        "</p>\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 106,
      "metadata": {
        "id": "0liD2NOVM8yE"
      },
      "outputs": [],
      "source": [
        "#Artists dataframe\n",
        "artists = spark.read.option(\"header\",\"true\")\\\n",
        "    .csv('/content/artists-data.csv')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OQn1a3PqM80l"
      },
      "source": [
        "#  Exercise 4 - (3 points) - Artist's genre\n",
        "\n",
        "<p align=\"justify\">\n",
        "<font size=\"3\">\n",
        "Provide a program that finds the artists for which the genre is not specified.\n",
        "\n",
        "</font>\n",
        "</p>\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#First 5 rows of Artists dataframe\n",
        "artists.show(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QoXC6whkJZv-",
        "outputId": "e9c63b03-2d9e-483f-9e73-ca5fe117a4fc"
      },
      "execution_count": 107,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------------+-----+----------+-------------------+-----+--------------------+\n",
            "|           Artist|Songs|Popularity|               Link|Genre|              Genres|\n",
            "+-----------------+-----+----------+-------------------+-----+--------------------+\n",
            "|    10000 Maniacs|  110|       0.3|    /10000-maniacs/| Rock|Rock; Pop; Electr...|\n",
            "|        12 Stones|   75|       0.3|        /12-stones/| Rock|Rock; Gospel/Reli...|\n",
            "|              311|  196|       0.5|              /311/| Rock|Rock; Surf Music;...|\n",
            "|    4 Non Blondes|   15|       7.5|    /4-non-blondes/| Rock|Rock; Pop/Rock; R...|\n",
            "|A Cruz Está Vazia|   13|         0|/a-cruz-esta-vazia/| Rock|                Rock|\n",
            "+-----------------+-----+----------+-------------------+-----+--------------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#We use a MySQL query approach to filter the artists \n",
        "artists.filter(\"Genre IS NULL\").show(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nPLVbLY_JxIz",
        "outputId": "99aac60c-c5ec-443c-dcf3-c52ce1c069da"
      },
      "execution_count": 108,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+-----+----------+----+-----+------+\n",
            "|Artist|Songs|Popularity|Link|Genre|Genres|\n",
            "+------+-----+----------+----+-----+------+\n",
            "+------+-----+----------+----+-----+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6hM-HsHaN7fv"
      },
      "source": [
        "#  Exercise 5 - (3 points) - Duplicates\n",
        "\n",
        "<p align=\"justify\">\n",
        "<font size=\"3\">\n",
        "Provide a program that removes the duplicates in the artists (also in this case the URL is the key).\n",
        "\n",
        "</font>\n",
        "</p>\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 109,
      "metadata": {
        "id": "rN84mQ22N7fv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2e88f355-00b3-4313-96c6-de21d71ee96c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+-----+----------+--------------------+---------+--------------------+\n",
            "|              Artist|Songs|Popularity|                Link|    Genre|              Genres|\n",
            "+--------------------+-----+----------+--------------------+---------+--------------------+\n",
            "|           DJ Khaled|  108|       2.7|         /dj-khaled/|  Hip Hop|Hip Hop; Rap; Bla...|\n",
            "|       Dying Kingdom|   10|         0|     /dying-kingdom/|     Rock|Rock; Hard Rock; ...|\n",
            "|         ExaltaSamba|  238|        13|      /exalta-samba/|    Samba|               Samba|\n",
            "|   Gabriella Caetano|    2|         0| /gabriella-caetano/|Sertanejo|           Sertanejo|\n",
            "|Luiz Henrique & F...|   43|         0|/luiz-henrique-e-...|Sertanejo|           Sertanejo|\n",
            "+--------------------+-----+----------+--------------------+---------+--------------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "### Write here your code\n",
        "unique_artists = artists.dropDuplicates(['Link'])\n",
        "unique_artists.show(5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R812Vv_yN7fw"
      },
      "source": [
        "#  Exercise 6 - (4 points)\n",
        "\n",
        "<p align=\"justify\">\n",
        "<font size=\"3\">\n",
        "Provide a program that using dataframe return the 100 most popular artists and the lyrics of their songs.\n",
        "</font>\n",
        "</p>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 111,
      "metadata": {
        "id": "89GH5qOlN7fw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1cb7d02c-739c-42ef-ecbb-ec087c88878d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------------+--------------------+--------------------+\n",
            "|       Artist|               SName|               Lyric|\n",
            "+-------------+--------------------+--------------------+\n",
            "|4 Non Blondes|           What's Up|Twenty-five years...|\n",
            "|4 Non Blondes|            Spaceman|Starry night brin...|\n",
            "|4 Non Blondes|     Pleasantly Blue|Every time you wa...|\n",
            "|4 Non Blondes|               Train|What ya gonna do ...|\n",
            "|4 Non Blondes|Calling All The P...|How can you tell,...|\n",
            "+-------------+--------------------+--------------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "### Write here your code\n",
        "\n",
        "#Load in the lyrics data first \n",
        "lyrics_data = spark.read.option(\"header\",\"true\")\\\n",
        "    .csv('/content/lyrics-data.csv')\n",
        "\n",
        "\n",
        "#We perform inner join of the top artists with their songs using Alink as the key\n",
        "\n",
        "best_artists = unique_artists.sort(unique_artists.Popularity.desc())\\\n",
        "    .limit(100).select(\"Link\",\"Artist\")\n",
        "\n",
        "best_artists_lyrics = best_artists.join(lyrics_data, best_artists.Link == lyrics_data.ALink)\n",
        "artists_lyrics = best_artists_lyrics.select(\"Artist\",\"SName\",\"Lyric\")\n",
        "\n",
        "artists_lyrics.show(5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DatBVcKUM8yn"
      },
      "source": [
        "# 2 - Bonus \n",
        "\n",
        "\n",
        "<p align=\"justify\">\n",
        "<font size=\"3\">\n",
        "Using the approach you prefer (just Dataframes, hybrid approach)  :\n",
        "    \n",
        "* the 10 most common words in the lyrics of each artist\n",
        "* the 10 most common words for each genre. For this question we can use the primary genre of the artist.\n",
        "\n",
        "</font>\n",
        "</p>\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h3EIzkQFM8yo"
      },
      "outputs": [],
      "source": [
        "# Write here your code and the detailed description of the MapReduce algorithm.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "anaconda-cloud": {},
    "colab": {
      "name": "ass4_map_reduce_spark_colab.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    },
    "name": "BE4-Spark.ipynb"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}